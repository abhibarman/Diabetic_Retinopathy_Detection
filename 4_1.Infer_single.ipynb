{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml import Model, Logger\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications.efficientnet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "from utility import preprocess_image, OptimizedRounder,mapping\n",
    "from clearml import Task, TaskTypes\n",
    "from PIL import Image\n",
    "import os\n",
    "import shap\n",
    "from lime import lime_image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import img_to_array,load_img\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task.init(project_name='Diabetic_Retinopathy_Detection', \n",
    "                 task_name='Retinopathy Inference', \n",
    "                 task_type=TaskTypes.inference,\n",
    "                 reuse_last_task_id=False\n",
    "                 )\n",
    "\n",
    "# Create an input model using the ClearML ID of a model already registered in the ClearML platform\n",
    "model_path = Model(model_id=\"48a76b1277154398991d1d079db968ae\").get_local_copy()\n",
    "model = load_model(model_path)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"inference_Data/001639a390f0.png\"\n",
    "x_val = np.empty((1, 224, 224, 3), dtype=np.uint8)\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img)\n",
    "img_array = preprocess_input(img_array)\n",
    "x_val[0,:,:,:] = img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print(f'Model Prediction: {y_pred}')\n",
    "\n",
    "optR = OptimizedRounder()\n",
    "coefficients = [0.49964604, 1.55479703, 2.4369177,  3.26701671] # Learnt while training the efficient net model.\n",
    "print(f'Coefficients: {coefficients}')\n",
    "prediction = optR.predict(y_pred, coefficients)\n",
    "#print('Optirmized Prediction :{y_val_pred}')\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = shap.maskers.Image('inpaint_telea',x_val[0].shape)\n",
    "explainer = shap.Explainer(model, masker)\n",
    "\n",
    "# here we use 500 evaluations of the underlying model to estimate the SHAP values\n",
    "shap_values = explainer(x_val, max_evals=500)\n",
    "shap.image_plot(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.image_plot(shap_values)\n",
    "fig = plt.gcf()\n",
    "fig.savefig('shap_explanation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = shap.image_plot(shap_values, x_val, show=True)\n",
    "print(ret)\n",
    "#plt.show()\n",
    "# get current figure and save it\n",
    "fig = plt.gcf()\n",
    "fig.savefig('shap_image_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "shap.image_plot(shap_values, x_val)\n",
    "st.pyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIME \n",
    "# Create a LIME explainer\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(x_val[0], model.predict, top_labels=1, hide_color=0, num_samples=1000)\n",
    "temp, mask = explanation.get_image_and_mask(0, positive_only=False, num_features=10, hide_rest=False)\n",
    "fig, axe = plt.subplots(figsize=(7, 3.5))\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "axe.text(180, 190, 'Predicted:'+mapping.get(int(prediction[0].item())), bbox=dict(facecolor='red', alpha=0.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Model(model_id=\"48a76b1277154398991d1d079db968ae\").get_local_copy()\n",
    "model = load_model(model_path)\n",
    "image_path = 'inference_Data/001639a390f0.png'\n",
    "x_val = np.empty((1, 224, 224, 3), dtype=np.uint8)\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img)\n",
    "img_array = preprocess_input(img_array)\n",
    "x_val[0,:,:,:] = img_array\n",
    "\n",
    "masker = shap.maskers.Image('inpaint_telea',x_val[0].shape)\n",
    "explainer = shap.Explainer(model, masker)\n",
    "\n",
    "# here we use 500 evaluations of the underlying model to estimate the SHAP values\n",
    "shap_values = explainer(x_val, max_evals=500)\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.image_plot(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(x_val[0], model.predict, top_labels=1, hide_color=0, num_samples=1000)\n",
    "temp, mask = explanation.get_image_and_mask(0, positive_only=False, num_features=10, hide_rest=False)\n",
    "fig, axe = plt.subplots(figsize=(7, 3.5))\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "axe.text(180, 190, 'Predicted:'+mapping.get(int(prediction[0].item())), bbox=dict(facecolor='red', alpha=0.0))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phm_dr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
