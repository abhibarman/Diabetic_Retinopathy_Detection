{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml import Model, Logger\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from utility import preprocess_image, OptimizedRounder, mapping\n",
    "from clearml import Task, TaskTypes\n",
    "from PIL import Image\n",
    "import os\n",
    "import shap\n",
    "from lime import lime_image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import img_to_array,load_img\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from keras.applications.efficientnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-s (Functiona  (None, 7, 7, 1280)       20331360  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,332,641\n",
      "Trainable params: 20,178,769\n",
      "Non-trainable params: 153,872\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model_path = Model(model_id=\"48a76b1277154398991d1d079db968ae\").get_local_copy()\n",
    "model = load_model('/home/abhijitbarman/abhijit/WS/DR/models_downloaded/beeef706a848dd90b41ebd61f8cd356c.final_model.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "# Set N to the number of rows in val_df\n",
    "N = val_df.shape[0]\n",
    "# Create an empty numpy array of dimensions (N, im_size, im_size, 3) to hold the preprocessed validation images\n",
    "x_val = np.empty((N, im_size, im_size, 3), dtype=np.uint8)\n",
    "# Loop over each image ID in the id_code column of the val_df dataframe\n",
    "for i, image_id in enumerate(tqdm_notebook(val_df['id_code'])):\n",
    "    # Call the preprocess_image function to preprocess the image with the desired size im_size\n",
    "    preprocessed_image = preprocess_image(f'{image_id}', desired_size=im_size)\n",
    "    # Add the preprocessed image to the x_val numpy array\n",
    "    x_val[i, :, :, :] = preprocessed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('jarvis_data/names.txt')\n",
    "print(data.shape)\n",
    "data['diagnosis'] = data.diagnosis.astype(float)\n",
    "y_true = data.diagnosis.values.tolist()\n",
    "ids = data.id_code.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD & PREPARE DATA\n",
    "#y_true = data.diagnosis.values.tolist()\n",
    "x_val = np.empty((data.shape[0], 224, 224, 3), dtype=np.uint8)\n",
    "counter = 0\n",
    "multiplier = 0\n",
    "incr = 1\n",
    "for i,file in enumerate(data.id_code.values): \n",
    "    if i ==0:\n",
    "        multiplier = 5 \n",
    "    if i !=0 and i % multiplier ==0:\n",
    "        counter += 1 \n",
    "        incr += 1\n",
    "        multiplier = multiplier + 5 * incr \n",
    "    file_path = 'jarvis_data/Train/'+ mapping.get(counter)+'/'+file\n",
    "    img = load_img(file_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    x_val[i,:,:,:] = preprocess_input(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print(f'Model Prediction: {y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()\n",
    "#optR.fit(y_pred, y_true)\n",
    "coefficients = coefficients = [0.49964604, 1.55479703, 2.4369177,  3.26701671] # Learnt while training the efficient net model.\n",
    "print(f'Coefficients: {coefficients}')\n",
    "y_val_pred = optR.predict(y_pred, coefficients)\n",
    "y_val_pred  = np.squeeze(y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual':y_true,'Predicted':y_val_pred, 'id_code':ids})\n",
    "print(df)\n",
    "df.to_csv('demo_inference.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('demo_inference.csv')\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.Actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds = results[results['Actual']==results['Predicted']]\n",
    "correct_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds.to_csv('correct_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = correct_preds.groupby('Actual').head(2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.empty((X.shape[0], 224, 224, 3), dtype=np.uint8)\n",
    "for i,code,y in zip(list(range(X.shape[0])),X.id_code.values, X.Actual.values):\n",
    "    file_path = 'jarvis_data/Train/'+ mapping.get(int(y)) +'/'+code\n",
    "    #x_val[i,:,:,:] = preprocess_image(file_path)\n",
    "\n",
    "    img = load_img(file_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    x_val[i,:,:,:] = preprocess_input(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('X.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.maskers.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = shap.maskers.Image('inpaint_telea',x_val[0].shape)\n",
    "explainer = shap.Explainer(model, masker)\n",
    "# here we use 500 evaluations of the underlying model to estimate the SHAP values\n",
    "shap_values = explainer(x_val, max_evals=500,)\n",
    "#shap.image_plot(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for svalue in range(shap_values.shape[0]):\n",
    "    print(svalue)\n",
    "    shap.image_plot(shap_values[svalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEEP EXPLAINER\n",
    "masker = shap.maskers.Image('inpaint_telea',x_val[0].shape)\n",
    "explainer = shap.DeepExplainer(model, x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here we use 500 evaluations of the underlying model to estimate the SHAP values\n",
    "shap_values = explainer.shap_values(x_val)\n",
    "#shap.image_plot(shap_values)\n",
    "\n",
    "for svalue in range(shap_values.shape[0]):\n",
    "    print(svalue)\n",
    "    shap.image_plot(shap_values[svalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIME \n",
    "\n",
    "# Create a LIME explainer\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "for i in range(x_val.shape[0]):\n",
    "    # Explain the predictions made by the model\n",
    "    explanation = explainer.explain_instance(x_val[i], model.predict, top_labels=1, hide_color=0, num_samples=1000)\n",
    "    temp, mask = explanation.get_image_and_mask(0, positive_only=False, num_features=10, hide_rest=False)\n",
    "    fig, axe = plt.subplots(figsize=(7, 3.5))\n",
    "    plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "    #if y_true[i]:\n",
    "    #   axe.text(180, 180, 'Actual:'+y_true[i], bbox=dict(facecolor='red', alpha=0.0))\n",
    "    #axe.text(180, 190, 'Predicted:'+y_val_pred[i], bbox=dict(facecolor='red', alpha=0.0))\n",
    "    plt.show()\n",
    "    fig.savefig('out_images/lime/'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the two folders where your images are located\n",
    "folder1 = \"out_images/shap\"\n",
    "folder2 = \"out_images/lime\"\n",
    "\n",
    "# Load the images from the two folders\n",
    "images1 = [plt.imread(f\"{folder1}/{i}.png\") for i in range(0, 10)]\n",
    "images2 = [plt.imread(f\"{folder2}/{i}.png\") for i in range(0, 10)]\n",
    "\n",
    "dignosis = [int(x) for x in X.Actual.values]\n",
    "dignosis_text = [mapping.get(i) for i in dignosis]\n",
    "\n",
    "preds = []\n",
    "for txt in dignosis_text:\n",
    "    array_created = np.full((20, 20, 3),255, dtype = np.uint8)\n",
    "    preds.append(array_created)\n",
    "\n",
    "#images3 = [plt.imread(f\"{folder2}/{i}.png\") for i in range(0, 10)]\n",
    "\n",
    "    \n",
    "#dignosis_text\n",
    "\n",
    "\n",
    "# Create a figure with two columns and ten rows\n",
    "fig, axes = plt.subplots(nrows=10, ncols=3, figsize=(15, 30),gridspec_kw={\"width_ratios\": [1, 1,1]})\n",
    "\n",
    "# Set the titles for each column\n",
    "axes[0][0].set_title(\"Actual          SHAP\")\n",
    "axes[0][1].set_title(\"LIME\")\n",
    "axes[0][2].set_title(\"ACTUAL/PREDICTED\")\n",
    "\n",
    "# Loop through each row and plot the corresponding images from each folder\n",
    "for i in range(10):\n",
    "    axes[i][0].imshow(images1[i])\n",
    "    axes[i][1].imshow(images2[i])\n",
    "    axes[i][2].imshow(preds[i])\n",
    "    axes[i][2].text(10,10,dignosis_text[i],bbox=dict(facecolor='Green', alpha=0.5))\n",
    "    axes[i][2].text(10,15,dignosis_text[i],bbox=dict(facecolor='Orange', alpha=0.5))\n",
    "    \n",
    "    #axe.text(25, 25, 'Predicted:'+mapping.get(int(prediction[0].item())), bbox=dict(facecolor='red', alpha=0.0))\n",
    "\n",
    "# Hide the x and y axis ticks for all subplots\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "# Adjust the spacing between the subplots\n",
    "#plt.subplots_adjust(hspace=-0.6)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the two folders where your images are located\n",
    "folder1 = \"out_images/shap\"\n",
    "folder2 = \"out_images/lime\"\n",
    "\n",
    "# Load the images from the two folders\n",
    "images1 = [plt.imread(f\"{folder1}/{i}.png\") for i in range(0, 10)]\n",
    "images2 = [plt.imread(f\"{folder2}/{i}.png\") for i in range(0, 10)]\n",
    "\n",
    "dignosis = [int(x) for x in X.Actual.values]\n",
    "dignosis_text = [mapping.get(i) for i in dignosis]\n",
    "\n",
    "preds = []\n",
    "for txt in dignosis_text:\n",
    "    array_created = np.full((20, 20, 3),255, dtype = np.uint8)\n",
    "    preds.append(array_created)\n",
    "\n",
    "#images3 = [plt.imread(f\"{folder2}/{i}.png\") for i in range(0, 10)]\n",
    "\n",
    "    \n",
    "#dignosis_text\n",
    "\n",
    "\n",
    "# Create a figure with two columns and ten rows\n",
    "fig, axes = plt.subplots(nrows=10, ncols=2, figsize=(8,30),gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "\n",
    "# Set the titles for each column\n",
    "axes[0][0].set_title(\"Actual          SHAP\")\n",
    "#axes[0][1].set_title(\"LIME\")\n",
    "axes[0][1].set_title(\"ACTUAL/PREDICTED\")\n",
    "\n",
    "# Loop through each row and plot the corresponding images from each folder\n",
    "for i in range(10):\n",
    "    axes[i][0].imshow(images1[i])\n",
    "    #axes[i][1].imshow(images2[i])\n",
    "    axes[i][1].imshow(preds[i])\n",
    "    axes[i][1].text(7,5,dignosis_text[i],bbox=dict(facecolor='Green', alpha=0.5))\n",
    "    axes[i][1].text(7,15,dignosis_text[i],bbox=dict(facecolor='Orange', alpha=0.5))\n",
    "    \n",
    "    #axe.text(25, 25, 'Predicted:'+mapping.get(int(prediction[0].item())), bbox=dict(facecolor='red', alpha=0.0))\n",
    "\n",
    "# Hide the x and y axis ticks for all subplots\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "# Adjust the spacing between the subplots\n",
    "#plt.subplots_adjust(hspace=-0.6)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP 2\n",
    "# select a set of background examples to take an expectation over\n",
    "import shap\n",
    "background = x_val\n",
    "\n",
    "\n",
    "shap.explainers._deep.deep_tf.op_handlers[\"AddV2\"] = shap.explainers._deep.deep_tf.passthrough #this solves the \"shap_ADDV2\" problem but another one will appear\n",
    "shap.explainers._deep.deep_tf.op_handlers[\"FusedBatchNormV3\"] = shap.explainers._deep.deep_tf.passthrough #this solves the next problem which allows you to run the DeepExplainer.\n",
    "shap.explainers._deep.deep_tf.op_handlers[\"DepthwiseConv2dNative\"] = shap.explainers._deep.deep_tf.passthrough #this solves the next problem which allows you to run the DeepExplainer.\n",
    "#e = shap.DeepExplainer(model, images)\n",
    "\n",
    "# explain predictions of the model on three images\n",
    "e = shap.DeepExplainer(model, background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...or pass tensors directly\n",
    "# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\n",
    "shap_values = e.shap_values(x_val[0:2],check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phm_dr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
